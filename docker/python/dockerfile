FROM nvidia/cuda:12.0.0-cudnn8-devel-ubuntu20.04

ARG BASE_PATH=/app

# optは動作しないので注意
WORKDIR $BASE_PATH

RUN ln -sf /usr/share/zoneinfo/Asia/Tokyo /etc/localtime
# 日本のミラーサイトに変更
RUN sed -i.bak -e "s%http://archive.ubuntu.com/ubuntu/%http://ftp.iij.ad.jp/pub/linux/ubuntu/archive/%g" /etc/apt/sources.list

RUN apt-get update
RUN apt-get -y install cmake git python3 python3-pip

ARG CMAKE_ARGS="-DLLAMA_CUBLAS=on" 
ARG FORCE_CMAKE=1
RUN pip install llama-cpp-python huggingface-hub

# llama.cppを準備
WORKDIR $BASE_PATH
RUN git clone https://github.com/ggerganov/llama.cpp.git
WORKDIR $BASE_PATH/llama.cpp/
RUN make LLAMA_CUBLAS=1
RUN pip install -r requirements.txt

# huggingfaceからダウンロード
# WORKDIR $BASE_PATH
# RUN python3 download.py
# RUN pip install huggingface-hub
# RUN python3 llama.cpp/convert.py ELYZA-model --outfile ELYZA-model.gguf
