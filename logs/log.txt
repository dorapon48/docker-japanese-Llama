2023/12/21
dockerでELYZA-japanese-Llama-2-7bを使えるようにしてみる。
huggingface-hubとやらからダウンロードしてみる
elyza/ELYZA-japanese-Llama-2-7b-fast-instruct
ダウンロードと最適化を行ったやつを別イメージで作成し、完成したggufファイルをコピーするのがよさそう
とりあえず必要そうなものはそろったか？

2023/12/22
GPUを使うにはいろいろとめんどくさそうだったが、
pytorchの何かがありそう

2023/12/23
おっもいんでnvidia/cuda:12.3.1-devel-ubuntu20.04を使う
お、いろいろやってたら行けた
とりあえず、nvidia/cuda:12.0.0-cudnn8-runtime-ubuntu20.04を使う、PCのcudaのバージョンと合わせた方がいいらしい
少し低いバージョンを使えばいいのかも
うまくいった！
/optはnividiaが使うみたいなので/appに変更すること
よし、サーバーを立ててみる
llama.cppとダウンロードは別にする
なんかよくわかんないCOPYエラーが発生している
エラーは表示されていないが、ファイルが存在しなくなる。場所の問題か？
場所の問題だったらしい、マウントするところにコピーしていたのでおかしくあとから上書きしていたのかな
マウントするには最新の注意を払おう
ダウンロード系はoptに突っ込んどく
dockerfileを書き換えるともうダウンロードが走ると考えていいのでしばらくコメントアウトしてもいいかもしれない

2023/12/24
/opt/llama.cpp/server -m /app/llama.cpp/models/llama-2-7b-chat.ggmlv3.q2_K.gguf -c 2048 --host localhost --port 30000
サーバーを作るの面倒みたいねどうにかせねば

2023/01/18
pythonのバージョンが古い可能性がある
ちがうっぽい
llama-cpp-pythonのバージョンを下げたらいけた
dekita!
ポートのエラーが出ていたが、0.0.0.0に設定することでlocalhostでつながるようになった
python3 -m llama_cpp.server --model llama.cpp/models/llama-2-7b-chat.ggmlv3.q2_K.gguf
Llama.cppをダウンロードする必要がなくなったためdownloaderの方で処理してからと思ったが、
そもそも処理済みのものがあるらしいのでそれを持ってきた方が楽
と思ったがちょっと怖いので真面目にする

2023/01/19
全てを1つのdockerファイルでやるのは無理があると思うので、ダウンロード専用のdockerfileを作成する
shファイルにまとめることでbuild時間を少なくしているらしい
僕もそうしよう
...マウントしているところにコピーするのはやめよう
動作をdownloadディレクトリですることにした
shファイルの一番上の部分は、#!/usr/bin/env bashにしておくのが無難

2023/01/21
convert.pyの処理がうまくいかない
どうも、tokenizer.modelが見当たらないほかのelyzaのやつには入っているのでそれが問題かも
elyza/ELYZA-japanese-Llama-2-7b-fast-instruct、elyza/ELYZA-japanese-Llama-2-7b-fastには入っていない
elyza/ELYZA-japanese-Llama-2-7b-instructで試してみる
.envファイルを用意して、ダウンロードを制御する
fileサイズが大きすぎるので、通信環境がいいとこでやる

2023/01/22
何とかなった
docker-compose --profile download up --build
でダウンロードできる
.envファイルにhuggingfaceのidと、保存するファイルの名前を入力すれば動くはず
次は、mainの方

2023/01/23
 curl -s -XPOST -H 'Content-Type: application/json' localhost:8000/v1/chat/completions -d '{"messages": [{"role": "user", "content": "Could you introduce yourself?"}]}'
 実験
 curl -X 'POST' \
  'http://localhost:8000/v1/chat/completions' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "messages": [
    {
      "content": "富士山は何メートル？",
      "role": "user"
    }
  ]
}'